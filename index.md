
# Dan Rosenbaum

<img style="float: left; margin: 0px 20px 20px 0px; max-width: 350px;" src="/dan_rosenbaum.jpeg" alt="Dan Rosenbaum" width="50%" />

I am a research scientist at DeepMind working on machine learning and computer vision. 

Before joining DeepMind, I completed my PhD at the Hebrew University of Jerusalem in 2016, advised by [Yair Weiss](http://www.cs.huji.ac.il/~yweiss/), studying generative models for low-level vision problems. 
<a href="/DanRosenbaumThesis.pdf">[thesis]</a>

[Publications](https://scholar.google.com/citations?user=a6CNXV8AAAAJ&hl=en) &nbsp;&nbsp;&nbsp; [Research Statement](/dan_rosenbaum_research_statement.pdf) &nbsp;&nbsp;&nbsp; [CV](/dan_rosenbaum_CV.pdf)


<p style="clear: left;"></p>

I am interested in computational models of vision and 3D scene understanding, and using generative approaches that model vision as an inverse problem. 
- learning models of 3D scenes that can be used for inference.
- learning discrete representations that divide scenes into objects, types, and concepts.
- embodied generative models that can control key variables in the data they are trained to capture.
- scientific imaging, where knowledge of the image acquisition process is used to infer the underlying 3D scene.

I co-organised a workshop at NeurIPS 2019 titled "**Perception as Generative Reasoning: Structure, Causality, Probability**".  
See the [website](https://pgr-workshop.github.io) for all papers, invited talks and videos.

[Publications](https://scholar.google.com/citations?user=a6CNXV8AAAAJ&hl=en) &nbsp;&nbsp;&nbsp; [Research Statement](/dan_rosenbaum_research_statement.pdf) &nbsp;&nbsp;&nbsp; [CV](/dan_rosenbaum_CV.pdf)

## Research

<img style="float: left; margin: 0px 20px 20px 0px; max-width: 200px;" src="/inverse_graphics.png" alt="learning inverse graphics" width="20%" />
**Learning inverse graphics** - In the inverse graphics approach vision problems are formulated as inference using a forward model that captures the image generation process. I am currently exploring different setups for learning forward models that can be used for efficient inference.
<p style="clear: left;"></p><hr style="height:1px;">
<img style="float: left; margin: 0px 20px 20px 0px; max-width: 200px;" src="/protein.png" alt="protein structure" width="20%" />
**Protein Structure** - Understanding the 3D structure of proteins is a fundamental problem in biology, with the potential of unlocking a better understanding of the various functions of proteins in biological mechanisms, and accelerating drug discovery. In currently ongoing work, I am studying models of protein structure that explicitly reason in 3D space, predicting structure using probabilistic inference methods.
<p style="clear: left;"></p><hr style="height:1px;">
<img style="float: left; margin: 0px 20px 20px 0px; max-width: 200px;" src="/gqn_attention.gif" alt="3D scene understanding with Generative Query Networks (GQN)" width="20%" />
**3D scene understanding with Generative Query Network (GQN)** - In this paper ([Science](http://science.sciencemag.org/content/360/6394/1204)) we show how implicit scene understanding can emerge from training a model to predict novel views of random 3D scenes ([video](https://youtu.be/G-kWNQJ4idw)). In a follow-up paper ([arXiv](https://arxiv.org/abs/1807.03149)) we extend the model to use attention over image patches, improving its capacity to model rich environments like Minecaft. We study the camera pose estimation problem comparing an inference method with a generative model to a direct discriminative approach ([video](https://youtu.be/iHEXX5wXbCI), [datasets](https://github.com/deepmind/gqn-datasets)).   
<p style="clear: left;"></p><hr style="height:1px;">
<img style="float: left; margin: 0px 20px 20px 0px; max-width: 200px;" src="/np.gif" alt="Neural processes" width="20%" />
**Neural processes** - We introduce conditional neural processes ([arXiv](https://arxiv.org/abs/1807.01613)) and neural processes ([arXiv](https://arxiv.org/abs/1807.01622)), that are trained to predict values of functions given a context of observed function evaluations. These models provide a general framework for dealing with uncertainty, demonstrating fast adaptivity, and allowing a smooth transition between a prior model that is not conditioned on any data, and  flexible posterior models which can be conditioned on more and more data. In follow-up work we extend the model with an attention mechanism over context points ([arXiv](https://arxiv.org/abs/1901.05761)) and study different training objectives ([pdf](http://bayesiandeeplearning.org/2018/papers/92.pdf)).
<p style="clear: left;"></p><hr style="height:1px;">

## Contact

<img style="float: left; margin: 0px 20px 20px 0px; max-width: 150px;" src="/dan_rosenbaum.png" alt="Dan Rosenbaum" width="15%" />
danro@google.com 

[twitter.com/danrsm](https://twitter.com/danrsm)


